{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/2 周一\n",
    "全新的一周，开始新篇章！！！\n",
    "\n",
    "**首先应对的是 关于LLM llama**\n",
    " - 模型架构没有那么难，所以不要害怕\n",
    " - 主要花大量时间精力去准备数据\n",
    " - scaling law 预测大模型\n",
    " - 机器集群训练大模型的挑战性\n",
    "\n",
    "当让也学习到一些新东西；首先是回忆算 $attention$ 的时候是下一个 Q 去乘 所有的 K、V ，然后使用 $GQV$ 可以降低存储\n",
    "\n",
    "--------\n",
    "接下来的工作指导：\n",
    "1. 希望接下来能研究一下 LLM 相关的工作，能做下去\n",
    "2. 看一看后续的论文精读，能不能继续找到一些灵感\n",
    "3. 可以思考 $CLIP$ 文本结合的 $DETR$ 目标检测任务，可以在短时间内做出成果\n",
    "\n",
    "我是`有时间试错`的，不要急！！！\n",
    "可恶，一写到这就有点着急了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/3 周二\n",
    "现在是晚上十点，总结时间。所以今天干嘛了？     \n",
    "Neural Corpus Indexer 这篇文章，看了LM讲解，自己看了看论文。 发在nips上的文章      \n",
    "发现对文档检索这个方向有点了解，多看一点没问题，技术迁移嘛。三个月做一个[**ideal**]没问题，做就行了。 just do it\n",
    "      \n",
    "自从自己投过文章后，现在会更注重论文写作这一块，确实很有技巧，好的写作胜过技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/4 周四\n",
    "论文由于没有引用期刊论文被退回，昨天到今天基本忙于修改论文。      \n",
    "但是我真的感觉效率好低，往这一坐就不想干（哭）。   \n",
    "\n",
    "差不多看完了 NCI 这篇文章，感觉写的确实有技巧，在有限的篇幅里把自己做的事情交代清楚。\n",
    "- 同时，注意到把自己的训练设置说的很清楚，评测标准也表达清楚，这很难得。   \n",
    "- 但是，实验也是简单陈述，分析就是一本正经胡扯了。\n",
    "\n",
    "就是发现自己 transform 还是有所欠缺，还有 seq2seq 模型，再了解一下吧，搞熟一点，下次就可以乱编公式了，哈哈哈哈哈！！！     \n",
    "比较自己的论文就是缺一点公式为自己的论文增添一点玄幻色彩。  \n",
    "\n",
    "--------\n",
    "又开始回忆过去，我的脑袋有点乱，本来充满希望的。怎么回事啊，一直缠着走不开了。   \n",
    "谈一次恋爱，痛苦这么久，真的令人伤心。   \n",
    "你说我明天能不能调整好状态，我肯定说不能，又开始循环了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/9 周一\n",
    "不知不觉，怎么就到9号了呀，时间过的好快。   \n",
    "6/7/8在生病 哭   \n",
    "总结今天把审稿意见写了，保底这篇文章能中了，运气挺好的！！！！！  \n",
    "   \n",
    "#### 总结上周干了啥：  \n",
    "主要就是阅读语言模型类文章，然后找思路，有一定收获，但是需要总结。\n",
    "明天我将继续语言类模型研究，这周必须拿下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/10 周二\n",
    "哎呀，头疼，感觉病越来越严重了。但是，但是，还是要寻找一下研究思路。     \n",
    "资源算力不够，期望能寻找到不消耗算力，简单的方向：\n",
    "- 利用好预训练好的模型，做$fine-tune$ **(vit; clip)**\n",
    "- 数据增强，一些即插即用的模块\n",
    "- 定义新的任务，目标函数，topic，新的损失函数\n",
    "- 多模态、强化学习、对比学习、无监督都拿来用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9/12 周四\n",
    "\n",
    "![NCI总览图](./image/NCI.jpg)\n",
    "\n",
    "#### 1. A Neural Corpus Indexer for Document Retrieval (NCI)\n",
    "- 使用[**K-means**]聚类算法将文档映射到 *docid*。\n",
    "\n",
    "- 用一个预训练好的模型从文档中抽取 *query* ，这样 *query* 由两部分组成。\n",
    "    - Generated Query；\n",
    "    - Ground-Truth Query；\n",
    "    \n",
    "- 最后使用一个标准的 *seq2seq* 模型将 *query* 作为输入预测 *docid*。\n",
    "    - 设计 PAWA Decoder 层级结构预测标号；\n",
    "    - 损失由分类损失和两种 *query* 的对比损失组成；\n",
    "\n",
    "![InstructGPT结构](./image/InstructGPT.jpg)\n",
    "\n",
    "#### 2. Training language models to follow instructions with human feedback (InstructGPT)\n",
    "- 人工收集和API收集一个高质量的数据集有监督的微调 **GPT3**，训练一个 *SFT*(supervised fine-tuning) 模型。\n",
    "\n",
    "- 以 *SFT* 模型为基础根据模型输出结果排序训练一个奖励模型 *RM*(reward model)，使得模型输出结果更符合人的偏好。\n",
    "    - 人工对9个输出结果排序\n",
    "    - 使用排序损失 **pair-wise ranking loss**   \n",
    "![pair-wise ranking loss](./image/pairwise_ranking_loss.jpg)\n",
    "\n",
    "- 训练最终的强化学习模型 *RL*(reinforement learning)，使用强化学习策略 **PPO**。      \n",
    "    - 第一项由 RM 提供标签计算损失；\n",
    "    - 第二项 KL 散度，保证模型与原始 SFT 模型不要偏离太远；\n",
    "    - 第三项引入原始的预训练损失，维持模型语言任务上的能力；   \n",
    "![PPO损失函数](./image/PPO.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
