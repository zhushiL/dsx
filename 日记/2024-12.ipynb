{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "12月的开始，先给自己定一个整体的目标。这个学期已经快结束了，感觉自己的进度有限，这是一件很折磨人的事情，自己在外漂流忍受艰辛，总要留下什么吧。目前确定自己要做 **SAM** 相关工作，这是一件值得开心的事情，明确了自己要努力的方向，以及这次感觉自己对[`热点`]的感知应该是比较准确的。在拥有一篇论文的情况下，其实是可以申请博士的，但是学校应该是不太能令人如意的。\n",
    "\n",
    "**ICML 2025 1月 --- ICCV 2025 3月 --- NeurIPS 2025 5月 --- AAAI 2026 8月中**    \n",
    "离梦想最近的一次,这一次的顶会必须要拿下!!! 希望到月底可以开始做实验。    \n",
    "年轻是应该奋斗的，不管是生活还是科研还是爱情，我希望自己一直保持对生活的热爱，拥抱世界。少一些对外界事物的敏感，其实世界很美好呀，独处时享受自己的时光，在一起时感受彼此的爱意，不需要一直证明，世界已经很爱我了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12/2 周一\n",
    "从 **github** 上下载一个项目，根据项目创建一个新的虚拟环境。可通过命令：$\\textbf{pip install -e .}$安装该环境里所有 python package，关于包的说明一般包含在文件 *setup.py* 里面。 \n",
    "     \n",
    "研究了 sam2 代码的使用：    \n",
    "```\n",
    "predictor.reset_state(inference_state)   #初始化状态   \n",
    "predictor.add_new_points_or_box    #对指定帧添加点或框的 prompt    \n",
    "predictor.propagate_in_video   #根据 prompt 对整个视频预测 \n",
    "```    \n",
    "/// 可以在中途添加预测，然后传播到整个视频。重新预测的话需要初始化状态。     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12/3 周二\n",
    "**SAM2** ImageEncoder 由两部分组成：Hierarchical ViT[1] 和 remove CNN FpnNeck      \n",
    "主要研究了 Hiera 的结构：使用最简单的层级式 *ViT* 结构结合 *MAE* 的代理任务实现强大的性能。    \n",
    "- 大量使用窗口注意力实现高效计算，结合少量全局注意力实现全局特征交互。     \n",
    "- 采用标准的多头注意力机制，注意力换成窗口注意力（在小窗口中计算注意力，窗口数量挪到 batch 维度）。    \n",
    "- QKV 不是相等，是将上层输出经过线性层将 dim 扩充三倍，然后分离出 QKV，这样维持整体 shape 不变。   \n",
    "- 实现层级转变时 Q转换成特征图使用$(2\\times2)$池化，高宽减半。最后使用线性投影将 dim 变为原来两倍。\n",
    "- 4个stage，patch_size=4 1024->256->128->64->32\n",
    "\n",
    "[1] Ryali, Chaitanya, et al. \"Hiera: A hierarchical vision transformer without the bells-and-whistles.\" *International Conference on Machine Learning(ICML).* PMLR, 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12/4 周三\n",
    "1. 首先是关于 `SAM2` 的研究\n",
    "    - **hiera** 依靠 **attention block** 堆叠而成，每个 **block** 设置是否要`层级变换`和`窗口注意力`。   \n",
    "    - **block** 的堆叠组成 **stage** ，每个 **stage** 包含一个层级，高宽减半，维度翻倍。    \n",
    "    - 参数 **return_interm_layers** 决定返回每个 **stage** 的输出还是只返回最后的输出。**output** 是一个 list。\n",
    "\n",
    "2. 然后抽空写了一下 `cover letter`。    \n",
    "    又浪费了十天时间，在论文重投回去要写 cover letter ，修改作者也要在其中表明，并且写出作者贡献。好在最后靠`小婷`收获了一些写信的技巧。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12/6 周五\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
